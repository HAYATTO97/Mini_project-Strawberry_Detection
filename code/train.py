from ultralytics import YOLO
import os
import cv2
import numpy as np
from thop import profile
import torch
import time
import csv
from itertools import product

# ì—¬ëŸ¬ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë° ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ
# === ê³µí†µ ê¸°ë°˜ ì„¤ì • ===
base_config = {
    "batch_size": 16,
    "lrf": 0.01
}

# === ì¡°í•©í•  í•­ëª©ë“¤ ===
models = ["yolo11n-seg.pt"]
optimizers = ["SGD", "AdamW"]
epochs_list = [100, 1000]
imgsz_list = [640, 768, 896, 1024]
lr0_list = [0.01, 0.001]

# === ì¡°í•© ìƒì„± ===
experiments = []

for model, optimizer, epochs, imgsz, lr0 in product(models, optimizers, epochs_list, imgsz_list, lr0_list): 
    # ì €ì¥ í´ë”ë¥¼ ìœ„í•´ run_name ìƒì„±
    model_base = model.replace(".pt", "")
    run_name = f"strawberry_{model_base}_{optimizer.lower()}"
    if epochs != 100:
        run_name += f"_e{epochs}"
    if imgsz != 640:
        run_name += f"_img{imgsz}"
    if lr0 != 0.01:
        run_name += f"_lr{lr0}"

    config = {
        "model_name": model,
        "run_name": run_name,
        "epochs": epochs,
        "imgsz": imgsz,
        "batch_size": base_config["batch_size"],
        "lr0": lr0,
        "lrf": base_config["lrf"],
        "optimizer": optimizer
    }

    experiments.append(config)

for i, exp in enumerate(experiments):
    # === [0] ì €ì¥ ê²½ë¡œ ë° ëª¨ë¸ ê²½ë¡œ í™•ì¸ ===
    project_dir = "/home/cv_task/Seungun/strawberry/nbt/original/outputs_3w"
    run_name = exp["run_name"]
    save_dir = os.path.join(project_dir, run_name)
    best_model_path = os.path.join(save_dir, "weights", "best.pt")

    # âŒ ì´ë¯¸ í•™ìŠµí•œ ê²½ìš° ìŠ¤í‚µ
    if os.path.exists(best_model_path):
        print(f"â­ï¸  ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸: {run_name}, ê±´ë„ˆëœë‹ˆë‹¤.")
        continue

    # === [1] ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ ===
    model = YOLO(exp["model_name"])

    results = model.train(
        data="/home/cv_task/Seungun/strawberry/nbt/original/data_3w.yaml",
        epochs=exp["epochs"], imgsz=exp["imgsz"], batch=exp["batch_size"],
        lr0=exp["lr0"], lrf=exp["lrf"], optimizer=exp["optimizer"],
        amp=True, workers=0,
        verbose=False,
        project=project_dir, name=run_name, exist_ok=True
    )

    # === [2] í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ===
    best_model_path = os.path.join(save_dir, "weights", "best.pt")
    model = YOLO(best_model_path)

    # === [3] ê²€ì¦ ì´ë¯¸ì§€ ì˜ˆì¸¡ ì‹œê°í™” ë° ì €ì¥ ===
    image_dir = "/home/cv_task/Seungun/strawberry/nbt/original/data_3w/images/val"
    label_dir = "/home/cv_task/Seungun/strawberry/nbt/original/data_3w/labels/val"
    output_dir = os.path.join(save_dir, "val_predictions")
    os.makedirs(output_dir, exist_ok=True)
    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]
    images = sorted([f for f in os.listdir(image_dir) if f.lower().endswith((".jpg", "JPG"))])[:10]

    for image_name in images:
        img_path = os.path.join(image_dir, image_name)
        label_path = os.path.join(label_dir, os.path.splitext(image_name)[0] + ".txt")
        save_path = os.path.join(output_dir, image_name)

        img = cv2.imread(img_path)
        if img is None:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
            continue
        h, w = img.shape[:2]

        if os.path.exists(label_path):
            with open(label_path, "r") as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 7 and len(parts[1:]) % 2 == 0:
                        cls = int(parts[0])
                        points = np.array(list(map(float, parts[1:])), dtype=np.float32).reshape(-1, 2)
                        points[:, 0] *= w
                        points[:, 1] *= h
                        pts_int = np.round(points).astype(np.int32)
                        color = colors[cls % len(colors)]
                        cv2.polylines(img, [pts_int], isClosed=True, color=color, thickness=2)
                        cv2.putText(img, f"GT:{cls}", tuple(pts_int[0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        r = model(img_path)[0]
        if r.masks is not None and r.masks.data is not None:
            for i, mask in enumerate(r.masks.data):
                cls = int(r.boxes.cls[i].item())
                conf = r.boxes.conf[i].item()
                mask_np = mask.cpu().numpy().astype(np.uint8) * 255
                mask_np = cv2.resize(mask_np, (w, h), interpolation=cv2.INTER_NEAREST)
                contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(img, contours, -1, (0, 0, 255), 2)
                if contours and len(contours[0]) > 0:
                    x, y, w_box, h_box = cv2.boundingRect(contours[0])
                    cv2.putText(img, f"P:{cls} {conf:.2f}", (x, y - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        cv2.imwrite(save_path, img)
        print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {save_path}")

    # === [4] ëª¨ë¸ ë¦¬ì†ŒìŠ¤ ì¸¡ì • ë° ì €ì¥ ===
    print("\nğŸ“Š ëª¨ë¸ ë¦¬ì†ŒìŠ¤ ì¸¡ì • ì¤‘...")
    dummy_input = torch.randn(1, 3, 640, 640).to(model.device)
    model.model.to(model.device)

    flops, params = profile(model.model, inputs=(dummy_input,), verbose=False)

    torch.cuda.synchronize()
    start = time.time()
    _ = model.model(dummy_input)
    torch.cuda.synchronize()
    end = time.time()

    inference_time = (end - start) * 1000  # ms
    fps = 1000 / inference_time

    csv_path = os.path.join(save_dir, "model_resource.csv")
    with open(csv_path, mode="w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["Model", "Params(M)", "FLOPs(G)", "Inference time(ms)", "FPS"])
        writer.writerow([
            "yolo11m-seg",
            f"{params / 1e6:.2f}",
            f"{flops / 1e9:.2f}",
            f"{inference_time:.2f}",
            f"{fps:.2f}"
        ])

    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ ë° ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {best_model_path}")
    print(f"ğŸ–¼ï¸ ì˜ˆì¸¡ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print(f"ğŸ“„ ë¦¬ì†ŒìŠ¤ ì €ì¥ ìœ„ì¹˜: {csv_path}")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    torch.cuda.empty_cache()